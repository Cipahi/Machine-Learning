{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Understand Collaborative Filtering From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to different types of Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-User Approach \n",
    "Also known as \"Neighborhood-based approach\", \"User-User Collaborative Filtering\", it calculates the similarity between users and use it as the weight to predict the target item. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Moving Rating](./_pic/MovieRatingExample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we want to know whether if we should recommend Fargo to Ken or not. Using User-User approach, we firstly calculate the similiarity between each user to Ken. Typically, similiarity can be calculated using pearson correlation. To make a prediction, we take the Fargo's rating from each User as value(- as 0, + as 1) and calculate the weighted sum of it using the similarity between each user. The Denominator is not \"n\" since it's the weighted sum. Instead of divided equally by 4, the similar the user is, the more weight it should be given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ p(X_i) = \\frac{\\sum_{i=1}^n Y_i * r(X, Y)}{\\sum_{i=1}^n |r(X, Y)|}, \\text{where n=4}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X$: target user\n",
    "\n",
    "$Y$: other users\n",
    "\n",
    "$n$: number of users\n",
    "\n",
    "$Y_1$: Amy's rating on Fargo, which is -\n",
    "\n",
    "r(X, Y): when i = 1, it represents the pearson correlation between Ken($X$) and Amy($Y$). X, Y are both a vector of length 4.\n",
    "\n",
    "$p(X_i)$: the final predicted value for whether if we should recommend Fargo to Ken or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-Item Approach \n",
    "This approach is simply an inversion of the neighborhood-based approach. The intuition is that instead of recommending using the similarity between users, we recommend it based on the similarity between items.\n",
    "\n",
    "Based on the same example above, to predict whether if we should recommend Fargo to Ken, we calculate the similarity between each items. The rating for Fargo and Pulp Fiction are the same, which means that people tend to have similar rating for these two items, so we may predict Ken will also like Fargo. In the form of equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ p(X_i) = \\frac{\\sum_{i=1}^n Y_i * r(X, Y)}{\\sum_{i=1}^n |r(X, Y)|}, \\text{where n=4}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X$: target item\n",
    "\n",
    "$Y$: other items\n",
    "\n",
    "$n$: number of items\n",
    "\n",
    "$Y_1$: The piano's rating by Ken, which is +.\n",
    "\n",
    "r(X, Y): when i = 1, it represents the pearson correlation between Fargo($X$) and Piano($Y$). X, Y are both a vector of length 4.\n",
    "\n",
    "$p(X_i)$: the final predicted value for whether if we should recommend Fargo to Ken or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering can also be formulated as a classification problem. Once the user ratings are converted into\n",
    "the following screenshot's format, almost any supervised learning method can be used to classify unseen items. Pazzani and Billsus, some recommender system researchers, first reduce the dimensionality of the vectors by applying singular value decomposition and then use a neural network as a learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Moving Rating Classification](./_pic/MovieRatingExample-Classification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "* 'memory based', 'model based' and 'hybrid' are different types of Collaborative Filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MovieLens Dataset to implement Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be downloaded [here](https://grouplens.org/datasets/movielens/100k/).\n",
    "\n",
    "According to GroupLens, MovieLens data sets were collected by the GroupLens Research Project\n",
    "at the University of Minnesota.\n",
    " \n",
    "This data set consists of:\n",
    "\t* 100,000 ratings (1-5) from 943 users on 1682 movies\n",
    "\t* Each user has rated at least 20 movies\n",
    "    * Simple demographic info for the users (age, gender, occupation, zip)\n",
    "    * Genre information of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/johnnychiu/Desktop/MyFiles/learning/Machine-Learning/RecommenderSystem/ml-100k\n"
     ]
    }
   ],
   "source": [
    "cd ml-100k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to get the rating matrix which each row represent each user and the value of each column represent the rating this particular user gave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = np.zeros((n_users, n_items))\n",
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4., ...,  0.,  0.,  0.],\n",
       "       [ 4.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 5.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  5.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In supervised learning, separate data into training and testing dataset, we usually do random sampling to rows of the dataframe. The reason is that we want to fix a function to the training dataset and use the function to predict the outcome of the testing dataset.\n",
    "\n",
    "However, for recommender systems with collaborative filtering (no features), this just won't work anymore, because all of the items/users need to be available when the model is first built. We do need the rating data for each user to calculate their recommendation items, in this case, movies. Since we have already known that each users has rated at least 20 movies. We then randomly take 10 rating out of these 20+ movies and assign them to test dataset.\n",
    "\n",
    "(I am not sure how to calculate the mse using the pred of train and test yet. It's not clear since pred of train should have more rating than test. How can they compare with each other? )\n",
    "\n",
    "We will only use the rated movies in the test dataset to calculate the mean square error(MSE). That is, for train dataset, we will keep only the index of non-zero value from test dataset, and use them to calculate the MSE with test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in xrange(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=10, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train\n",
      "(943, 1682)\n",
      "[[ 5.  3.  4. ...,  0.  0.  0.]\n",
      " [ 4.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  5.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "\n",
      "#Test\n",
      "(943, 1682)\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 5.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(ratings)\n",
    "print '#Train'\n",
    "print train.shape\n",
    "print train\n",
    "print '\\n'\n",
    "\n",
    "print '#Test'\n",
    "print test.shape\n",
    "print test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function calculates the cosine similarity, ie pearson correlation between each user using the input dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a recommender system using collaborative filtering\n",
    "1. calcuate similarity\n",
    "2. predict the probability using User-User and Item-Item approach\n",
    "3. validating the result using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_similarity(ratings, kind='user', epsilon=1e-9):\n",
    "    # epsilon -> small number for handling dived-by-zero errors\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        sim = ratings.T.dot(ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_similarity = fast_similarity(train, kind='user')\n",
    "item_similarity = fast_similarity(train, kind='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 943)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.14723095,  0.04579818, ...,  0.11663262,\n",
       "         0.18089804,  0.36751597],\n",
       "       [ 0.14723095,  1.        ,  0.07608248, ...,  0.11787781,\n",
       "         0.19125926,  0.0819063 ],\n",
       "       [ 0.04579818,  0.07608248,  1.        , ...,  0.143708  ,\n",
       "         0.12051638,  0.02956977],\n",
       "       ..., \n",
       "       [ 0.11663262,  0.11787781,  0.143708  , ...,  1.        ,\n",
       "         0.1062942 ,  0.05239333],\n",
       "       [ 0.18089804,  0.19125926,  0.12051638, ...,  0.1062942 ,\n",
       "         1.        ,  0.17675665],\n",
       "       [ 0.36751597,  0.0819063 ,  0.02956977, ...,  0.05239333,\n",
       "         0.17675665,  1.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print user_similarity.shape\n",
    "user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_fast_simple(ratings, similarity, kind='user'):\n",
    "    if kind == 'user':\n",
    "        return similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif kind == 'item':\n",
    "        return ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction = predict_fast_simple(train, item_similarity, kind='item')\n",
    "user_prediction = predict_fast_simple(train, user_similarity, kind='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user_prediction, item_prediction records the predict recommendation probability for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.24055006e+00,   7.74126048e-01,   4.59618296e-01, ...,\n",
       "          5.47242008e-04,   6.91019414e-03,   7.74567790e-03],\n",
       "       [  1.74732903e+00,   3.41433616e-01,   3.13708503e-01, ...,\n",
       "          3.45427384e-03,   3.08290521e-03,   2.01289791e-03],\n",
       "       [  1.29736821e+00,   3.30136379e-01,   2.61173855e-01, ...,\n",
       "          9.50596148e-03,   3.16705197e-03,   1.63376661e-03],\n",
       "       ..., \n",
       "       [  1.80659731e+00,   3.93393694e-01,   3.28852773e-01, ...,\n",
       "          2.41578076e-03,   4.24774455e-03,   1.12324913e-03],\n",
       "       [  1.88930554e+00,   5.99816782e-01,   3.19051195e-01, ...,\n",
       "          2.47856144e-03,   5.43287722e-03,   3.59721904e-03],\n",
       "       [  2.30551510e+00,   9.09929162e-01,   4.93472907e-01, ...,\n",
       "          7.86337360e-15,   7.94449896e-03,   7.59479840e-03]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print user_prediction.shape\n",
    "user_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 8.4931401358\n",
      "Item-based CF MSE: 11.6132805105\n"
     ]
    }
   ],
   "source": [
    "item_prediction = predict_fast_simple(train, item_similarity, kind='item')\n",
    "user_prediction = predict_fast_simple(train, user_similarity, kind='user')\n",
    "\n",
    "print 'User-based CF MSE: ' + str(get_mse(user_prediction, test))\n",
    "print 'Item-based CF MSE: ' + str(get_mse(item_prediction, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, User-User Approach is a better way for recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a recommender system using Top $K$ collaborative filtering\n",
    "We can attempt to improve our prediction MSE by only considering the top $k$ users who are most similar to the input user (or, similarly, the top $k$ items). That is, when we calculate the sums over $Y_i$, we only sum over the top $k$ most similar users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ p(X_i) = \\frac{\\sum_{i=1}^n Y_i * r(X, Y)}{\\sum_{i=1}^n |r(X, Y)|}, \\text{where n=k, instead of the total number of other users}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. calcuate similarity, which is the same as the previous one.\n",
    "2. predict the probability using the top $k$ User-User and Item-Item approach\n",
    "3. validating the result using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_topk(ratings, similarity, kind='user', k=40):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    if kind == 'user':\n",
    "        for i in xrange(ratings.shape[0]):\n",
    "            top_k_users = [np.argsort(similarity[:,i])[:-k-1:-1]]\n",
    "            for j in xrange(ratings.shape[1]):\n",
    "                pred[i, j] = similarity[i, :][top_k_users].dot(ratings[:, j][top_k_users]) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[i, :][top_k_users]))\n",
    "    if kind == 'item':\n",
    "        for j in xrange(ratings.shape[1]):\n",
    "            top_k_items = [np.argsort(similarity[:,j])[:-k-1:-1]]\n",
    "            for i in xrange(ratings.shape[0]):\n",
    "                pred[i, j] = similarity[j, :][top_k_items].dot(ratings[i, :][top_k_items].T) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[j, :][top_k_items]))        \n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k User-based CF MSE: 6.51275063533\n",
      "Top-k Item-based CF MSE: 7.74005106481\n"
     ]
    }
   ],
   "source": [
    "pred = predict_topk(train, user_similarity, kind='user', k=40)\n",
    "print 'Top-k User-based CF MSE: ' + str(get_mse(pred, test))\n",
    "\n",
    "pred = predict_topk(train, item_similarity, kind='item', k=40)\n",
    "print 'Top-k Item-based CF MSE: ' + str(get_mse(pred, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a recommender system using Bias-subtracted Collaborative Filtering\n",
    "Some user may tend to give lower ratings while some may tend to give generally higher ratings. It will affect the recommend probability since the user that has higher rating will affect the probabilty more than those who generally rates lower. \n",
    "\n",
    "Let us try subtracting each user's average rating when summing over similar user's ratings and then add that average back in at the end. We modify our equation to become:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ p(X_i) = \\bar{Y} + \\frac{\\sum_{i=1}^n (Y_i- \\bar{Y}) * r(X, Y)}{\\sum_{i=1}^n |r(X, Y)|}, \\text{where n=4}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "where $\\bar{Y}$ is user $Y$'s average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nobias(ratings, similarity, kind='user'):\n",
    "    if kind == 'user':\n",
    "        user_bias = ratings.mean(axis=1)\n",
    "        ratings = (ratings - user_bias[:, np.newaxis]).copy()\n",
    "        pred = similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "        pred += user_bias[:, np.newaxis]\n",
    "    elif kind == 'item':\n",
    "        item_bias = ratings.mean(axis=0)\n",
    "        ratings = (ratings - item_bias[np.newaxis, :]).copy()\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "        pred += item_bias[np.newaxis, :]\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias-subtracted User-based CF MSE: 8.7710448431\n",
      "Bias-subtracted Item-based CF MSE: 9.79353560567\n"
     ]
    }
   ],
   "source": [
    "user_pred = predict_nobias(train, user_similarity, kind='user')\n",
    "print 'Bias-subtracted User-based CF MSE: ' + str(get_mse(user_pred, test))\n",
    "\n",
    "item_pred = predict_nobias(train, item_similarity, kind='item')\n",
    "print 'Bias-subtracted Item-based CF MSE: ' + str(get_mse(item_pred, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation the Recommender System\n",
    "Let's look at our item similarity matrix and see if similar items \"make sense\". We input a selected movie, and check if the top 5 recommend movies are \"good\". There is a webiste called [themoviedb.org](themoviedb.org) which has a free API. If we have the IMDB \"movie id\" for a movie, then we can use this API to return the posters of movies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The movie_url doesn't work. I will skip this part) In u.item data, we have the movie_url for each movie. We can somehow use the movie_url to get the movie_id for each movie and send it as a parameter to themobedb.org's API to get the posters of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\r\n",
      "2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\r\n",
      "3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\r\n",
      "4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0\r\n",
      "5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 u.item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in movie data\n",
    "idx_to_movie = {}\n",
    "with open('u.item', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        info = line.split('|')\n",
    "        idx_to_movie[int(info[0])-1] = info[1]\n",
    "        \n",
    "def top_k_movies(similarity, mapper, movie_idx, k=6):\n",
    "    return [mapper[x] for x in np.argsort(similarity[movie_idx,:])[:-k-1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toy Story (1995)',\n",
       " 'Star Wars (1977)',\n",
       " 'Return of the Jedi (1983)',\n",
       " 'Independence Day (ID4) (1996)',\n",
       " 'Rock, The (1996)',\n",
       " 'Fargo (1996)']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0 # Toy Story\n",
    "movies = top_k_movies(item_similarity, idx_to_movie, idx)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lion King, The (1994)',\n",
       " 'Aladdin (1992)',\n",
       " 'Forrest Gump (1994)',\n",
       " 'Beauty and the Beast (1991)',\n",
       " 'Jurassic Park (1993)',\n",
       " 'E.T. the Extra-Terrestrial (1982)']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 70 # Lion King\n",
    "movies = top_k_movies(item_similarity, idx_to_movie, idx)\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "* http://recommender-systems.org/collaborative-filtering/\n",
    "* https://www.analyticsvidhya.com/blog/2016/06/quick-guide-build-recommendation-engine-python/\n",
    "* http://blog.ethanrosenthal.com/2015/11/02/intro-to-collaborative-filtering/\n",
    "* http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/recsys/1_ALSWR.ipynb\n",
    "\n",
    "Mathematical expressions reference\n",
    "* http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Typesetting%20Equations.html\n",
    "* http://csrgxtu.github.io/2015/03/20/Writing-Mathematic-Fomulars-in-Markdown/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
