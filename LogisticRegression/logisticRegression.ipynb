{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "* author: \"Johnny Chiu\"\n",
    "* date: \"11/7/2017\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "\n",
    "* Logistics Regression\n",
    "    * The idea behind logistics regression model\n",
    "    * The interpretaion of $\\beta_1$ in logistics regression\n",
    "    * Estimating the regression coefficients\n",
    "    * \n",
    "* Multinomial Logistics Regression\n",
    "    * Logistics Regression for Nominal Response\n",
    "    * Bayes Classification\n",
    "    * Logistics Regression for Ordinal Response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression\n",
    "\n",
    "### • The idea behind logistics regression model\n",
    "\n",
    "Logistic Regression is useful when the outcome of our regression model is categorical.\n",
    "Instead of using y, which we assume the value of it is categorical like {0,1}, {yes, no}, directly as our response variable, we models the probability that y belongs to a particular category. In other words, we build up a linear model on the log-odds (or logit). In the following paragraph, we denote the probability that y belongs to a particular category as $p(X) = Pr(Y=1|X)$ \n",
    "\n",
    "Since $p(X)$ is the probability that y belongs to a particular category, the value of it should be between 0 and 1. Therefore, we must model p(X) using a function that gives outputs between 0 and 1. Many functions meet this description. In logistic regression, we use the logistic function:\n",
    "\n",
    "$$ p(X)= \\frac{e^{\\beta_0+\\beta_1X}}{1+e^{\\beta_0+\\beta_1X}}  $$\n",
    "\n",
    "We can easily see that the output value of this model is within 0 and 1. When $\\beta_0+\\beta_1X$ goes to $\\infty$, $p(X)$ will be 1; When $\\beta_0+\\beta_1X$ goes to -$\\infty$, $p(X)$ will be 0.\n",
    "\n",
    "This is the model that we are going to use to build up our regression model on. To make the equation to become more interpretable, after a bit of manipulation, we can get the following one:\n",
    "\n",
    "$$ log(\\frac{p(X)}{1-p(X)})= \\beta_0+\\beta_1X $$\n",
    "\n",
    "In the left hand side of the equation, it is the log odd of the probability that y belongs to a particular category. For example, if the probability of a success event is 0.8, then the odd ratio will be 4. The higher odds we get, the more likely we will get a success event. \n",
    "\n",
    "The left-hand side is called the log-odds or logit, which is also the link function of logistics regression. We see that the logistic regression has a logit that is linear in $X$.\n",
    "\n",
    "For the illustration purpose, we can see the Example 6.3 from the textbook *Predictive Analytics: Paramertic Models for Regression and Classificantion*\n",
    "\n",
    "We can see that the model is fitted using the log odd as y and the Eduation level as x. When eduation level increase from 1 to 2, then the log odd of visit is increased by $\\beta_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](_pic/example_6.3_1.png)\n",
    "![](_pic/example_6.3_2.png)\n",
    "![](_pic/example_6.3_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • The interpretaion of $\\beta_1$ in logistics regression\n",
    "\n",
    "The above equation also equals:\n",
    "\n",
    "$$ \\frac{p(X)}{1-p(X)}= e^{\\beta_0+\\beta_1X}  $$\n",
    "\n",
    "Here we assume that the $beta_1$ we get is 0.3. From the above equation, we can see that when $x$ is increased by 1 unit, the odd ratio will increase by $e^{\\beta_1}$=`r exp(0.3)`. $\\beta_1$ means how much the log odd ratio will increase if our predictor $x$ is increased by 1 unit. In other words, if $x$ is increased by 1 unit, then the odds ratio will increase by $e^{\\beta_1}$. We can also get the increased probability of success from the increased odd ratio we get. For example, if the original $p(X)$ is 0.8, then our odds ratio is 4. When we increased x by 1, the odds ratio increased by $e^{\\beta_1}$=`r exp(0.3)`. Therefore, the increased odd ratio is `r 4*exp(0.3)`. We can then get that our increased $p(X)$ is `r 4*exp(0.3)/(1+4*exp(0.3))`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Estimating the regression coefficients\n",
    "\n",
    "***Why can't we use least square method to estimate the coefficient for logistic regression?***\n",
    "\n",
    "If we follow the same formula as linear regression, then the cost function is\n",
    "\n",
    "$$\\sum_{i=1}^{n} \\Big( y_i - log(\\frac{y_i}{1-y_i}) \\Big)^2$$\n",
    "\n",
    "The log term is either -$\\infty$ if $y_i=0$ or $\\infty$ if $y_i=1$. Even in the case that the response y is grouped, which means that we are trying to predict the success probability for each group, if the response for all the observations of $x_i$ within the group goes to 1, then log term will still be $\\infty$. Therefore, least square method cannot be used. To estimate the coefficient, we will need to use MLE method introduce as follows.\n",
    "\n",
    "***What is Maximum Likelihood Estimation(MLE)?***\n",
    "\n",
    "To explain MLE intuitively, we can think of it as this way:\n",
    "According to the observed fact, what is the process(or parameters) that will maximize the probability for us to get this outcome?\n",
    "There is one explaination from Quora that explain it very well:\n",
    "\n",
    "*You only get to see what the nature wants you to see. Things you see are facts. These facts have an underlying process that generated it. These process are hidden, unknown, needs to be discovered. Then the question is: Given the observed fact, what is the likelihood that process P1 generated it? What is the likelihood that process P2 generated it? And so on... One of these likelihoods is going to be max of all. MLE is a function that extracts that max likelihood.* \n",
    "\n",
    "*Think of a coin toss; coin is biased. No one knows the degree of bias. It could range from o(all tails) to 1 (all heads). A fair coin will be 0.5 (head/tail equally likely). When you do 10 tosses, and you observe 7 Heads, then the MLE estimator for the prob of head of this coin is 0.7.*\n",
    "\n",
    "*Think of a stock price of say, British Petroleum. BP was selling at \\$59.88 on April 23, 2010. By June 25, 2010 the price was down to \\$27.02. There could be several reasons for this fall. But the most likely reason could be the BP oil spill and the public sentiment. Stock price is the observed fact. The MLE will estimate the most likely underlying reason.*\n",
    "\n",
    "For example, if we have drawn 5 samples from a population, assume all the 5 samples are drawn from normal independent distribution, i.e., $Y_i ~ NID(\\mu, \\alpha^2)$, then the joint p.d.f. of $Y_1, \\dots, Y_n$ is the multiply of the five p.d.f. When we view the joint pdf of $Y_1, \\dots, Y_n$ as a function of $\\mu$ and $\\alpha$, it's actually the likelihood function, which is the probabilty that these 5 samples are drawn from the normal distribution with some certain $\\mu$ and $\\alpha$.\n",
    "\n",
    "Another example is that when we flip a coin for 4 times, with 3 head and 1 tail. What is the MLE estimator for the probabilty that the coin will show us head? The marginal distribution of $Y_i$ is $p_i$ when $y_i=head$ and $1-p_i$ when $y_i=tail$. Therefore, the joint pdf(aka likelihood function) is $p^3(1-p)$. By taking partial derivative and set it to 0 with respect to p, we can get our MLE of p to be 3/4.\n",
    "\n",
    "***How to use MLE to estimate the coefficient of logistic regression?***\n",
    "\n",
    "We are trying to find estimtaes for $\\beta_0$ and $\\beta_1$, when we plug in these estimators into the our first equation above, yields a number close to 1 for all the observed y equals to 1; close to 0 for all observed y equals to 0. We can formulized the likelehood function $L$ as following:\n",
    "\n",
    "$$ L = L(\\beta_0, \\beta_1) = \\displaystyle\\prod_{i=1}^{n} \\Big[ (p_i)^{y_i}(1-p_i)^{1-y_i} \\Big] = \\displaystyle\\prod_{i=1}^{n} \\Big( \\frac{p_i}{1-p_i} \\Big)^{y_i} \\times \\prod_{i=1}^{n} (1-p_i)$$\n",
    "\n",
    "By taking log from both side\n",
    "$$ ln(L) = \\displaystyle\\sum_{i=1}^{n} y_i ln\\Big( \\frac{p_i}{1-p_i}\\Big) + \\sum_{i=1}^{n} ln(1-p_i) =  \\displaystyle\\sum_{i=1}^{n} y_i(\\beta_0+\\beta_1 x_i) -  \\sum_{i=1}^{n} ln(1+ exp(\\beta_0+\\beta_1x_i)) $$\n",
    "\n",
    "The maximizing values can be found by setting the partial derivatives of $ln(L)$ with respect to $\\beta_0$ and $\\beta_1$.\n",
    "\n",
    "The main idea behind it is that for each observation, we are estimating a probability using the logistic function. Therefore, we can get an estimated probabilty for each observation. If the observed response for the observation is 1, then the estimated probabilty is $logisticFunction(x_i)$, where $\\beta_0$ and $\\beta_1$ is used in the logistic function. The likelihood of the observation will be the product of every observation. By taking the log of the likelihood function, it will be easier for us to do partial derivative and get the estimated $\\beta$s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Evaluating the correctness of the model\n",
    "\n",
    "***What are sensitivity, specifity, recall, precision and what is the rationale behind it?***\n",
    "![](_pic/precision_recall.png)\n",
    "\n",
    "* **Precision**: tp/(predicted positive) = tp/(tp + fp)\n",
    "* **Recall, Sensitivity**: tp/(real positive) = tp/(tp + fn)\n",
    "* **Specificity**: tn/(real negative)\n",
    "* **F1 score**: $\\frac{2PR}{P+R}$\n",
    "\n",
    "There is usually a tradeoff between precision and recall. Since if we want to get as much people as possible from the real positive cases, we can just predict everyone to be +. The recall will be 1. However, the precision will be low. Since out of the total predictive +, the true positive will be only small proportion of it. In other words, there will be lots of False positive.\n",
    "\n",
    "Let's take a typical cancer screening for example. When will we want to use Recall or Precision as our measure metric?\n",
    "If we have very expensive secondary cancer test, we would probably prefer precision to recall. When precision is high, it means that when I predict a patient has cancer, then the result is highly reliable(False positive is low). The tradeoff is that we may have chances that a person has cancer but we don’t predict it(We may have a high false negative). That’s why in this case, we may prefer precision to recall.\n",
    "\n",
    "If we have cheap secondary cancer test, and we can afford send lots of people to do this test. Then we would probably like our model to predict as more suspicious people as possible, and send them to do this test. In other words, we want high Recall, we want to get as much people as possible out of the real + cases(We may have a high false postive, but it's ok, since the cancer test is cheap and we can afford it).\n",
    "\n",
    "To sum up, when we use Recall as the measure, we prefer low false negative than high false positive, i.e, we prefer to get as many people to get the cancer test than ignore anyone who might have a cancer but we don't test it; when we use Precision as the measure, we prefer low false positive than high falsh negative, i.e., we prefer whenever we say a patient has cancer, we say it with high confidence, and there may be a lot of potential having cancer patient that we do not test on them.\n",
    "\n",
    "\n",
    "\n",
    "***What is ROC curve?***\n",
    "\n",
    "The ROC curve is created by plotting the true positive rate (TPR=$\\frac{tp}{\\text{#real positive cases}}$, i.e. Sensitivity) against the false positive rate (FPR=$\\frac{fp}{\\text{#real negative cases}}$, i.e. 1-Specificity) at various threshold settings. \n",
    "\n",
    "In the perfect case, where the distribution is perfectly separate for positve and negative cases, the Area under curve(AUC) is 1. In the case that the two distribution is overlapping, the curve will be a straight line with AUC 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • An example of building binary logistic regression\n",
    "![](_pic/binary_logistic_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer(1)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = response ~ days, family = binomial, data = df)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.9141  -0.9818   0.5792   0.8411   1.5923  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept)  3.81944    1.83518   2.081   0.0374 *\n",
       "days        -0.08648    0.04322  -2.001   0.0454 *\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 32.601  on 23  degrees of freedom\n",
       "Residual deviance: 27.788  on 22  degrees of freedom\n",
       "AIC: 31.788\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make Dataframe\n",
    "df = data.frame(days=c(21,24,25,26,28,31,33,34,35,37,43,49,51,55,25,29,43,44,46,46,51,55,56,58),\n",
    "                response=c(rep(1,14),rep(0,10)))\n",
    "\n",
    "# Fit binary logistic regression\n",
    "fit = glm(response ~ days, family=binomial, data=df)\n",
    "summary(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer(2)***\n",
    "\n",
    "From the result of our model, we can see that the 95% CI for $\\beta_{days}$=\n",
    "\n",
    "$$ -0.08648 \\pm 1.96 \\times 0.04322 = [-0.1711912, -0.0017688] $$\n",
    "Therefore, a 95% CI on the odds ratio equals the exponential of it, which is \n",
    "$$[exp(-0.1711912), exp(-0.0017688)] = [0.8426604, 0.9982328]   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer(3)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>real</th><th scope=col>predict</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1        </td><td>0.8811429</td></tr>\n",
       "\t<tr><td>1        </td><td>0.8511753</td></tr>\n",
       "\t<tr><td>1        </td><td>0.8398841</td></tr>\n",
       "\t<tr><td>1        </td><td>0.8279095</td></tr>\n",
       "\t<tr><td>1        </td><td>0.8018532</td></tr>\n",
       "\t<tr><td>1        </td><td>0.7573984</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " real & predict\\\\\n",
       "\\hline\n",
       "\t 1         & 0.8811429\\\\\n",
       "\t 1         & 0.8511753\\\\\n",
       "\t 1         & 0.8398841\\\\\n",
       "\t 1         & 0.8279095\\\\\n",
       "\t 1         & 0.8018532\\\\\n",
       "\t 1         & 0.7573984\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "real | predict | \n",
       "|---|---|---|---|---|---|\n",
       "| 1         | 0.8811429 | \n",
       "| 1         | 0.8511753 | \n",
       "| 1         | 0.8398841 | \n",
       "| 1         | 0.8279095 | \n",
       "| 1         | 0.8018532 | \n",
       "| 1         | 0.7573984 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  real predict  \n",
       "1 1    0.8811429\n",
       "2 1    0.8511753\n",
       "3 1    0.8398841\n",
       "4 1    0.8279095\n",
       "5 1    0.8018532\n",
       "6 1    0.7573984"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_response = predict(fit, newdata=df, type='response')\n",
    "real_response = df$response\n",
    "\n",
    "compare_df = data.frame(real = real_response, predict = predict_response)\n",
    "head(compare_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted value for the 24 patients in the sample is shown in the table above in the predict column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_optimal_p <- function(real_response, predict_response, p_threshold_list){\n",
    "  max_ccr= 0\n",
    "  optimal_p = 0\n",
    "  for (p in p_threshold_list){\n",
    "    pred = rep(0, 24)\n",
    "    pred[predict_response > p]=1\n",
    "    ccr = sum(diag(table(real=real_response, pred)))/ 24\n",
    "    \n",
    "    if (ccr > max_ccr){\n",
    "      max_ccr= ccr\n",
    "      optimal_p = p\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  \n",
    "  pred = rep(0, 24)\n",
    "  pred[predict_response > optimal_p]=1\n",
    "  confusion_table=table(real=real_response, pred)\n",
    "\n",
    "  confusion_table=table(real=real_response, pred)\n",
    "  sensitivity=confusion_table[2,2]/(confusion_table[2,1]+confusion_table[2,2])\n",
    "  specificity=confusion_table[1,1]/(confusion_table[1,1]+confusion_table[1,2])\n",
    "  precision=confusion_table[2,2]/(confusion_table[1,2]+confusion_table[2,2]) \n",
    "  f1_score=2*precision*sensitivity/(precision+sensitivity)\n",
    "  \n",
    "  return(data.frame(p=optimal_p, \n",
    "              ccr=max_ccr,\n",
    "              sensitivity=sensitivity, \n",
    "              specificity=specificity,\n",
    "              f1_score=f1_score))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sensitivity, specificity and the F1 score fo the optimal p∗ is shown in the table below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "|    p|  ccr| sensitivity| specificity|  f1_score|\n",
       "|----:|----:|-----------:|-----------:|---------:|\n",
       "| 0.51| 0.75|   0.7857143|         0.7| 0.7857143|"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(knitr)\n",
    "optimal = get_optimal_p(real_response, predict_response, seq(0.3,0.7,0.01))\n",
    "\n",
    "kable(optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer(4)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = response ~ days, family = binomial, data = df)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.9141  -0.9818   0.5792   0.8411   1.5923  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept)  3.81944    1.83518   2.081   0.0374 *\n",
       "days        -0.08648    0.04322  -2.001   0.0454 *\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 32.601  on 23  degrees of freedom\n",
       "Residual deviance: 27.788  on 22  degrees of freedom\n",
       "AIC: 31.788\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.75"
      ],
      "text/latex": [
       "0.75"
      ],
      "text/markdown": [
       "0.75"
      ],
      "text/plain": [
       "Area under the curve: 0.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAEDWlDQ1BJQ0MgUHJvZmlsZQAA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\nYEIM/D+sZ7IuLB6vdwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(pROC)\n",
    "\n",
    "summary(fit)\n",
    "plot.roc(real_response, fit$fitted.values, xlab=\"1-Specificity\")\n",
    "\n",
    "\n",
    "\n",
    "my_auc = auc(real_response, fit$fitted.values)\n",
    "my_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is **0.75**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multinomial Logistics Regression\n",
    "For the data that the outcome is nominal or ordinal, we cannot apply binary logistic regression to our data anymore. One reason is that usually both types of data have more than 2 categories, and ordinal data is a categorical, statistical data type where the variables have natural, ordered categories and the distances between the categories is not known.\n",
    "\n",
    "Let's see how we can build a regression model on these types of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Logistics Regression for Nominal Response\n",
    "Let's assume that we have 3 categorical responses(A,B,C) and 6 predictors including the intercept now. How do we build up a logistic regression model on it? One way to do it is to set one response category as reference and compare the probabilities of the remaining 2 responses to it. Let's denote the probability of response $y=k$ by $p_k=p_k(x)$, and set category $C$ as the reference. Then we have the following equations\n",
    "\n",
    "$$ \n",
    "\\begin{cases}\n",
    "    ln(\\frac{p_a}{p_c})=\\beta_{0a}+\\beta_{1a}x_1+ \\beta_{2a}x_2 + \\beta_{3a}x_3 + \\beta_{4a}x_4 + \\beta_{5a}x_5       & \\quad \\text{for category A}\\\\\n",
    "    ln(\\frac{p_b}{p_c})=\\beta_{0b}+\\beta_{1b}x_1+ \\beta_{2b}x_2 + \\beta_{3b}x_3 + \\beta_{4b}x_4 + \\beta_{5b}x_5  & \\quad \\text{for category B }\n",
    "  \\end{cases}\n",
    "$$\n",
    "More generally, we can rewrite it as:\n",
    "\n",
    "$$ ln(\\frac{p_k}{p_c})=\\beta_{0k}+\\beta_{1k}x_1+ \\beta_{2k}x_2 + \\beta_{3k}x_3 + \\beta_{4k}x_4 + \\beta_{5k}x_5   \\quad \\text{for k = a, b} $$\n",
    "Therefore, in our example, we will need to estimate $(3-1)*6=12$ different $\\beta$'s to build up a model.\n",
    "\n",
    "***How do we interpret the meaning of all the $\\beta_{ik}$ in the nominal logistic regression model?***\n",
    "\n",
    "The explanation is quoted from the textbook *Predictive Analytics: Paramertic Models for Regression and Classificantion* explain it very well:\n",
    "\n",
    "\"The interpretation of the coefficient $\\beta_{ik}$ is similar to that of the $\\beta_1$ coefficient for binary logistic regression. It is the change in the log-odds of response $k$={a or b} relative to that of the regerence category c when the predictor variable $x_{i}$ is increased by one unit keeping all other variables fixed. \n",
    "\n",
    "As an example, suppose $\\beta_{ik}$ then $exp(0.5)=1.649$. Hence the odds of outcome $k$ vesus outcome $c$ increased by a factor of $1.649$ if $x_i$ is increased by one unit\"\n",
    "\n",
    "***How to get the predicted probability for different category responses?***\n",
    "\n",
    "From the above equation, it follows that \n",
    "$$ p_k = p_c e^{\\beta_{0k}+\\beta_{1k}x_1+ \\beta_{2k}x_2 + \\beta_{3k}x_3 + \\beta_{4k}x_4 + \\beta_{5k}x_5}  $$\n",
    "If we denote category {A,B,C} as {1,2,3}, since $\\displaystyle\\sum_{k=1}^{3} p_k = 1$, we can see that\n",
    "\n",
    "$$ \\displaystyle\\sum_{k=1}^{3} p_k = p_a + p_b + p_c = p_c e^{\\beta_{0a}+\\beta_{1a}x_1+ \\beta_{2a}x_2 + \\beta_{3a}x_3 + \\beta_{4a}x_4 + \\beta_{5a}x_5} +p_c e^{\\beta_{0b}+\\beta_{1b}x_1+ \\beta_{2b}x_2 + \\beta_{3b}x_3 + \\beta_{4b}x_4 + \\beta_{5b}x_5} + p_c = 1  $$\n",
    "By solving $p_c$, we can get \n",
    "\n",
    "$$ p_c = \\frac{1}{1+ e^{\\beta_{0a}+\\beta_{1a}x_1+ \\beta_{2a}x_2 + \\beta_{3a}x_3 + \\beta_{4a}x_4 + \\beta_{5a}x_5} +  e^{\\beta_{0b}+\\beta_{1b}x_1+ \\beta_{2b}x_2 + \\beta_{3b}x_3 + \\beta_{4b}x_4 + \\beta_{5b}x_5}} = \\frac{1}{1+ \\sum_{j=1}^{2}e^{\\beta_{0j}+\\beta_{1j}x_1+ \\beta_{2j}x_2 + \\beta_{3j}x_3 + \\beta_{4j}x_4 + \\beta_{5j}x_5}} =$$\n",
    "\n",
    "$$ \\frac{1}{1+ \\sum_{j=1}^{2} exp(x' \\beta_j)} $$\n",
    "where $x' = (1, x_1, x_2, x_3, x_4, x_5)$ and $\\beta_j = \\beta_{0j} + \\beta_{1j} + \\beta_{2j}+ \\beta_{3j}+ \\beta_{4j} + \\beta_{5j}$\n",
    "\n",
    "Also, it follows that \n",
    "\n",
    "$$ \n",
    "\\begin{cases}\n",
    "    p_a=\\frac{exp(x' \\beta_a)}{1+ \\sum_{j=1}^{2} exp(x' \\beta_j)}       & \\quad \\text{for category A}\\\\\n",
    "    p_b=\\frac{exp(x' \\beta_b)}{1+ \\sum_{j=1}^{2} exp(x' \\beta_j)}  & \\quad \\text{for category B }\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "To sum up, for given $x$ vector, we can then calculate the probability of it for category {A,B,C}, and use the category with the highest predicted probability as the predicted category. We refer to the predicted value we get here as **Maximum probability classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Bayes Classification\n",
    "To go further, we can also use *prior probabilities* as the weight to the predicted probability that we calculate previous to get our bayes predicted probability. Suppose we have available prior probabilities, $\\pi_a, \\pi_b, \\pi_c = (0.2, 0.3, 0.5)$. Then by using the follow equation derived from *bayes formula*, we can get the *posterior probabilities*\n",
    "$$ \\hat{p_k}^*(x) = \\frac{\\pi_k \\hat{p_k}(x)}{\\sum_{j=1}^{m} \\pi_j \\hat{p_j}(x)} $$\n",
    "\n",
    "where $\\hat{p_k}(x)$ is the Maximum probability classifier we calculate previously. \n",
    "\n",
    "In our example, we can get the posterior probabilities as\n",
    "\n",
    "$$ \\hat{p_a}^*(x) = \\frac{0.2 \\times \\hat{p_a}(x)}{0.2 \\times \\hat{p_a}(x)+ 0.3 \\times \\hat{p_b}(x)+ 0.5 \\times \\hat{p_c}(x)} $$\n",
    "$$\\hat{p_b}^*(x) = \\frac{0.3 \\times \\hat{p_b}(x)}{0.2 \\times \\hat{p_a}(x)+ 0.3 \\times \\hat{p_b}(x)+ 0.5 \\times \\hat{p_c}(x)} $$\n",
    "$$\\hat{p_c}^*(x) = \\frac{0.5 \\times \\hat{p_c}(x)}{0.2 \\times \\hat{p_a}(x)+ 0.3 \\times \\hat{p_b}(x)+ 0.5 \\times \\hat{p_c}(x)} $$\n",
    "\n",
    "We refer to the predicted value we get here as **Bayes classifier**. One thing worth mention is that if the prior probabilities are equal, then the Bayes classifier is actually reduce to the maximum probability classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Logistics Regression for Ordinal Response\n",
    "\n",
    "For the categorical response that is ordinal, we build up our linear model on cumulative logits to capture the intrinsically ranked feature of it. The equation is shown as follows:\n",
    "\n",
    "$$ ln \\Big[\\frac{P(y \\le k)}{P(y > k)} \\Big]= \\beta_{0k}+ x'\\beta， \\text{k=1, ... , m-1}  $$\n",
    "Note that $P(y \\le m)=1$, and the equation can also be rewrite as \n",
    "$$ P(y \\le k) = \\frac{exp(\\beta_{0k}+ x'\\beta)}{1+exp(\\beta_{0k}+ x'\\beta)} $$\n",
    "\n",
    "\n",
    "If the category response in our preivous example {A,B,C} is ordinal, then the response value of the model we build is\n",
    "$$ \n",
    "\\begin{cases}\n",
    " ln \\Big[\\frac{P(y \\le a)}{P(y > a)} \\Big] = ln\\Big[\\frac{P(a)}{P(b \\text{ or } c)} \\Big] \\\\\n",
    " ln \\Big[\\frac{P(y \\le b)}{P(y > b)} \\Big] = ln\\Big[\\frac{P(a \\text{ or } b)}{P(c)} \\Big]\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Therefore, we can get that \n",
    "\n",
    "$$ \n",
    "\\begin{cases}\n",
    "  P(y \\le a) = \\frac{exp(\\beta_{0a}+ x'\\beta)}{1+exp(\\beta_{0a}+ x'\\beta)} \\\\\n",
    "  P(y \\le b) = \\frac{exp(\\beta_{0b}+ x'\\beta)}{1+exp(\\beta_{0b}+ x'\\beta)} \\\\ \n",
    "  P(y \\le c) = \\frac{exp(\\beta_{0c}+ x'\\beta)}{1+exp(\\beta_{0c}+ x'\\beta)}\n",
    "\\end{cases}\n",
    "$$\n",
    "$$ \n",
    "\\begin{cases}\n",
    "  p_a = P(y \\le a)\\\\\n",
    "  p_b = P(y \\le b) - P(y \\le a) \\\\ \n",
    "  p_c = P(y \\le c) - P(y \\le b)\n",
    "\\end{cases}\n",
    "$$\n",
    "We can also build up it and apply prior probability to make it into a Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • An example of building logistic regression for nomimal and ordinal response\n",
    "![](_pic/Exercise_6.5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer(a)***\n",
    "\n",
    "The total *True Positive* number is 29, and we have 51 observations in our test dataset. Therefore, the overall correct classification rate is approximately **0.5686**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      prediction\n",
      "actual  1  2  3\n",
      "     1  4  6  3\n",
      "     2  4  9  4\n",
      "     3  2  3 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.568627450980392"
      ],
      "text/latex": [
       "0.568627450980392"
      ],
      "text/markdown": [
       "0.568627450980392"
      ],
      "text/plain": [
       "[1] 0.5686275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(mlogit)\n",
    "\n",
    "# Read Data\n",
    "pregnancy_df = read.csv('_data/Pregnancy.csv', colClasses=c('factor','integer','factor','factor','factor'))\n",
    "\n",
    "# Transform Data\n",
    "pregnancy_df$Age <- relevel(pregnancy_df$Age, ref = \"2\")\n",
    "\n",
    "# Make train and test data\n",
    "train_indices <- seq(1, nrow(pregnancy_df), by=2)\n",
    "pregnancy_train <- pregnancy_df[train_indices,]\n",
    "pregnancy_test <- pregnancy_df[-train_indices,]\n",
    "\n",
    "# Build multinominal logistic regression\n",
    "pregnancy_train_mlogit = mlogit.data(data=pregnancy_train, choice='Duration', shape='wide')\n",
    "model_65_1 = mlogit(Duration ~ 0 | Nutrition+Alcohol+Smoking+Age,  data=pregnancy_train_mlogit)\n",
    "\n",
    "# Make prediction for pregnancy_test\n",
    "pregnancy_test_mlogit = mlogit.data(data=pregnancy_test, choice='Duration', shape='wide')\n",
    "pregnancy_prediction_df = data.frame(predict(model_65_1, newdata = pregnancy_test_mlogit))\n",
    "colnames(pregnancy_prediction_df) = c(1,2,3)\n",
    "pregnancy_prediction = as.integer(colnames(pregnancy_prediction_df)[apply(pregnancy_prediction_df,1,which.max)])\n",
    "\n",
    "# make confusion table\n",
    "pregnancy_acutal = pregnancy_test$Duration\n",
    "print(table(actual = pregnancy_acutal, prediction = pregnancy_prediction))\n",
    "\n",
    "# calculate the correct classification rate \n",
    "sum(diag(table(pregnancy_prediction, pregnancy_acutal)))/ dim(pregnancy_test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion table above, we can see that the correct classification rate for each category is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "| Category|      Rate|\n",
       "|--------:|---------:|\n",
       "|        1| 0.3076923|\n",
       "|        2| 0.5294118|\n",
       "|        3| 0.7619048|"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(knitr)\n",
    "table_65 <- data.frame(Category=c(1,2,3), Rate=c(4/13,9/17,16/21))\n",
    "kable(table_65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer(b)***\n",
    "\n",
    "The total *True Positive* number is 34, and we have 51 observations in our test dataset. Therefore, the overall correct classification rate is approximately **0.6667**, which is higher than the result of multinominal logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      prediction\n",
      "actual  1  2  3\n",
      "     1  5  5  3\n",
      "     2  3 10  4\n",
      "     3  2  0 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.666666666666667"
      ],
      "text/latex": [
       "0.666666666666667"
      ],
      "text/markdown": [
       "0.666666666666667"
      ],
      "text/plain": [
       "[1] 0.6666667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ordinal)\n",
    "\n",
    "# Transform Data\n",
    "pregnancy_train$Duration = as.ordered(pregnancy_train$Duration)\n",
    "\n",
    "# Build ordinal logistic regression\n",
    "model_65_2 = clm(Duration~ . ,data=pregnancy_train)\n",
    "\n",
    "# Make prediction for pregnancy_test (https://www.rdocumentation.org/packages/ordinal/versions/2015.6-28/topics/predict.clm)\n",
    "pregnancy_prediction_2 = predict(model_65_2, newdata = pregnancy_test, type=\"class\")$fit\n",
    "\n",
    "# make confusion table\n",
    "pregnancy_acutal = pregnancy_test$Duration\n",
    "print(table(actual = pregnancy_acutal, prediction = pregnancy_prediction_2))\n",
    "\n",
    "# calculate the correct classification rate \n",
    "sum(diag(table(actual = pregnancy_acutal, prediction = pregnancy_prediction_2))) / dim(pregnancy_test)[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reference\n",
    "\n",
    "* [How do you explain MLE intuitively from Quora](https://www.quora.com/How-do-you-explain-maximum-likelihood-estimation-intuitively)\n",
    "* [An Introduction to Statistical Learning\n",
    "with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "* Predictive Analytics: Paramertic Models for Regression and Classificantion by Ajit C. Tamhane and Edward C. Malthouse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
