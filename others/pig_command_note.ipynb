{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pig Command Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "* [Introduction](#intro)\n",
    "* [Syntax](#syntax)\n",
    "* [Reference](#refer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='intro'>Introduction</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pig is similar to Hive, is a layer on top of Java MapReduce Job\n",
    "* Pig provides a high-level language known as **Pig Latin**\n",
    "* To analyze data using Apache Pig, programmers need to write scripts using **Pig Latin** language. All these scripts are internally converted to Map and Reduce tasks. Apache Pig has a component known as **Pig Engine** that accepts the Pig Latin scripts as input and converts those scripts into MapReduce jobs.\n",
    "* The interactive shell of pig is called **Grunt**\n",
    "* Pig is a dataflow language, meaning that\n",
    "    * To perform a particular task Programmers using Pig, programmers need to write a Pig script using the Pig Latin language, and execute them using any of the execution mechanisms (Grunt Shell, UDFs, Embedded). After execution, these scripts will go through a series of transformations applied by the Pig Framework, to produce the desired output.\n",
    "* Pig is developed by Yahoo; Hive is developed by Facebook.\n",
    "\n",
    "\n",
    "Most of the information below are copied from [here](https://www.tutorialspoint.com/apache_pig/apache_pig_overview.htm).\n",
    "\n",
    "> **Pig vs SQL**\n",
    "\n",
    "<img src=\"pic/pigsql.png\" style=\"width: 400px;height: 210px;\"/>\n",
    "\n",
    "> **Pig vs Hive**\n",
    "\n",
    "Both Apache Pig and Hive are used to create MapReduce jobs. And in some cases, Hive operates on HDFS in a similar way Apache Pig does. In the following table, we have listed a few significant points that set Apache Pig apart from Hive.\n",
    "\n",
    "<img src=\"pic/pighive.png\" style=\"width: 400px;height: 210px;\"/>\n",
    "\n",
    "\n",
    "> **Apache Pig Execution Mechanisms**\n",
    "\n",
    "* **Interactive Mode (Grunt shell)** − You can run Apache Pig in interactive mode using the Grunt shell. In this shell, you can enter the Pig Latin statements and get the output (using Dump operator).\n",
    "* **Batch Mode (Script)** − You can run Apache Pig in Batch mode by writing the Pig Latin script in a single file with .pig extension.\n",
    "* **Embedded Mode (UDF)** − Apache Pig provides the provision of defining our own functions (User Defined Functions) in programming languages such as Java, and using them in our script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='syntax'>Syntax</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short summary of the dataflow \n",
    "\n",
    "* load data into grunt\n",
    "* do some manipulation of the loaded data and save as a new variable\n",
    "* use dump operator to see the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **getting into the Grunt shell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **check which pig mode in grunt shell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stackoverflow](https://stackoverflow.com/questions/33390099/how-to-know-pig-mode-in-grunt-shell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there are two mode of grunt shell, one is local mode, one is mapreduce mode\n",
    "# it'll list the path. If the path start with hdfs\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **execute pig script from command line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# usually use this if our input data source is in hdfs\n",
    "pig -f myscript.pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not so sure about when to use it. probably only when I want to load data from local file system.\n",
    "pig -x local Sample_script.pig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **pass parameter into pig script from command line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when running the script in cmd, put the parameter key-value as following\n",
    "pig -f filename.pig -param start_date=20170201 -param end_date=20170209 -param output=lmtmpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the pig script, refer to the parameter using $variable\n",
    "# here is an example\n",
    "STORE table_name INTO '/user/jochiu/$output';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **load data into pig in grunt shell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from local file\n",
    "# PigStorage indicate the deliminator of the file. \n",
    "customers = LOAD 'customers.txt' USING PigStorage(',');\n",
    "\n",
    "# from hdfs file\n",
    "customers = LOAD 'hdfs://customers.txt' USING PigStorage(',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customers = LOAD 'hdfs://localhost:9000/pig_data/customers.txt' USING PigStorage(',')\n",
    "   as (id:int, name:chararray, age:int, address:chararray, salary:int);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see a list of data types [here](https://www.tutorialspoint.com/apache_pig/pig_latin_basics.htm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **store / save data into hdfs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to specify a new folder otherwise it'll have 'output directory has already exist' error\n",
    "grunt> STORE user_244_top10 INTO 'hdfs://wolf.xxxxx.edu:8000/user/jchiu/pig/user244' USING PigStorage (',');\n",
    "\n",
    "# to get the file back into local file system in grunt shell\n",
    "grunt> fs -getmerge hdfs://wolf.iems.northwestern.edu:8020/user/jchiu/pig/user244 /home/jchiu/pig/user_244_top10.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **execute pig script in grunt shell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grunt> student = LOAD 'hdfs://localhost:9000/pig_data/student.txt' USING PigStorage(',') \n",
    "                as (id:int,name:chararray,city:chararray);\n",
    "grunt> Dump student;\n",
    "\n",
    "# Now, let us execute the above script from the Grunt shell using the exec command as shown below.\n",
    "grunt> exec /sample_script.pig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `run` instead. The difference between `exec` and the `run` command is that if we use `run`, the statements from the script are available in the command history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dump operator is used to run the Pig Latin statements and display the results on the screen. It is generally used for debugging Purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can see the output of the script using the Dump operator as shown below.\n",
    "grunt> Dump;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **invoke bash or hdfs dfs command within grunt shell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this works the same as using ls in cmd\n",
    "grunt> sh ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this works the same as using hdfs dfs -ls in cmd\n",
    "grunt> fs –ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **quit grunt shell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl+D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grunt> quit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **see the schema of the data**\n",
    "\n",
    "The describe operator is used to view the schema of a relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grunt> student = LOAD 'hdfs://localhost:9000/pig_data/student_data.txt' USING PigStorage(',')\n",
    "   as ( id:int, firstname:chararray, lastname:chararray, phone:chararray, city:chararray );\n",
    "\n",
    "grunt> describe student;    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **view the top n / top 5 rows **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_data = LIMIT student_details 4; \n",
    "\n",
    "DUMP limit_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_196 = FILTER movies BY user == 196;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Official Doc about dealing with Null](https://pig.apache.org/docs/r0.15.0/basic.html#nulls)\n",
    "\n",
    "In Pig Latin, nulls are implemented using the SQL definition of null as unknown or non-existent. Nulls can occur naturally in data or can be the result of an operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter null value\n",
    "records_null = FILTER records BY col is null;\n",
    "records_null = FILTER records BY col is not null;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **groupby and calculate avg**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [link](https://www.tutorialspoint.com/apache_pig/apache_pig_avg.htm)\n",
    "* [A list of function can be used after group by](https://www.tutorialspoint.com/apache_pig/apache_pig_eval_functions.htm)\n",
    "* [Blog: GROUP operator in Apache Pig](https://squarecog.wordpress.com/2010/05/11/group-operator-in-apache-pig/)\n",
    "* [Stackoverflow: counting elements for each group](https://stackoverflow.com/questions/25012396/counting-elements-for-each-group-using-pig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Goal: get the average movie rating order by avg_rating in descending order\n",
    "\n",
    "# input\n",
    "describe movies;\n",
    "# -> movies: {user: int,movie: int,rating: int,time: long}\n",
    "    \n",
    "# group by    \n",
    "movie_group = GROUP movies by movie;    \n",
    "describe movie_group;\n",
    "# -> movie_group: {group: int,movies: {(user: int,movie: int,rating: int,time: long)}}\n",
    "# noted that the first column name is group after the group by syntax\n",
    "\n",
    "movie_rating = FOREACH movie_group GENERATE group, AVG(movies.rating) AS avg_rating;\n",
    "describe movie_rating;\n",
    "# -> movie_rating: {group: int,avg_rating: double}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grunt> student_details = LOAD 'hdfs://localhost:9000/pig_data/student_details.txt' USING PigStorage(',')\n",
    "   as (id:int, firstname:chararray, lastname:chararray, age:int, phone:chararray, city:chararray, gpa:int);\n",
    "\n",
    "grunt> student_group_all = Group student_details All;\n",
    "\n",
    "grunt> Dump student_group_all;\n",
    "   \n",
    "(all,{(8,Bharathi,Nambiayar,24,9848022333,Chennai,72),\n",
    "(7,Komal,Nayak,24,9848022 334,trivendram,83),\n",
    "(6,Archana,Mishra,23,9848022335,Chennai,87),\n",
    "(5,Trupthi,Mohan thy,23,9848022336,Bhuwaneshwar,75),\n",
    "(4,Preethi,Agarwal,21,9848022330,Pune,93),\n",
    "(3 ,Rajesh,Khanna,22,9848022339,Delhi,90),\n",
    "(2,siddarth,Battacharya,22,9848022338,Ko lkata,78),\n",
    "(1,Rajiv,Reddy,21,9848022337,Hyderabad,89)})\n",
    "\n",
    "grunt> student_gpa_avg = foreach student_group_all Generate\n",
    "   (student_details.firstname, student_details.gpa), AVG(student_details.gpa); \n",
    "    \n",
    "grunt> Dump student_gpa_avg; \n",
    "\n",
    "(({(Bharathi),(Komal),(Archana),(Trupthi),(Preethi),(Rajesh),(siddarth),(Rajiv) }, \n",
    "  {   (72)   ,  (83) ,   (87)  ,   (75)  ,   (93)  ,  (90)  ,   (78)   ,  (89)  }),83.375)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **join**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inner join\n",
    "result = JOIN relation1 BY columnname, relation2 BY columnname;\n",
    "\n",
    "# Left outer join\n",
    "result = JOIN relation1 BY id LEFT OUTER, relation2 BY customer_id;\n",
    "\n",
    "# Right outer join\n",
    "result = JOIN relation1 BY id RIGHT OUTER, relation2 BY customer_id;\n",
    "\n",
    "# Full outer join\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **flatten**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Something can be useful: Multiple ORDER by on Desc in pig](https://stackoverflow.com/questions/32643195/multiple-order-by-on-desc-in-pig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='refer'>Reference</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Tutorialspoint: Pig Overview](https://www.tutorialspoint.com/apache_pig/apache_pig_overview.htm)\n",
    "* [Useful Pig Syntax Summary](http://timepasstechies.com/pig-tutorial-3-flatten-group-cogroup-cross-distinct-filter-foreach-limit-load-order-sample-split-store-stream-union-operators/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
