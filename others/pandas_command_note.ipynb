{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DVE Rental SQL Problems\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import pymysql\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\"dbname='dvdrental' user='' host='localhost' password=''\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = pd.read_sql_query('SELECT * from category',con=conn)\n",
    "film_category = pd.read_sql_query('SELECT * from film_category',con=conn)\n",
    "film = pd.read_sql_query('SELECT * from film',con=conn)\n",
    "language = pd.read_sql_query('SELECT * from language',con=conn)\n",
    "film_actor = pd.read_sql_query('SELECT * from film_actor',con=conn)\n",
    "inventory = pd.read_sql_query('SELECT * from inventory',con=conn)\n",
    "rental = pd.read_sql_query('SELECT * from rental',con=conn)\n",
    "payment = pd.read_sql_query('SELECT * from payment',con=conn)\n",
    "staff = pd.read_sql_query('SELECT * from staff',con=conn)\n",
    "actor = pd.read_sql_query('SELECT * from actor',con=conn)\n",
    "customer = pd.read_sql_query('SELECT * from customer',con=conn)\n",
    "address = pd.read_sql_query('SELECT * from address',con=conn)\n",
    "city = pd.read_sql_query('SELECT * from city',con=conn)\n",
    "country = pd.read_sql_query('SELECT * from country',con=conn)\n",
    "store = pd.read_sql_query('SELECT * from store',con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](_pic/DVD-Rental-ER-Diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question, Idea & Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### Get a list of actors with the first name Chris, Cameron, or Cuba.\n",
    "\n",
    "\n",
    "**> idea:**\n",
    "Use the ```SELECT``` & ```WHERE``` command to filter out the ideal rows.\n",
    " \n",
    "**> solution:**\n",
    "\n",
    "```\n",
    "    SELECT * from actor where first_name in ('Chris', 'Cameron', 'Cuba'); \n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**> note:**\n",
    "\n",
    "* `IN` lets you specify a lot of values that you would otherwise join together with an `OR` statement\n",
    "* We can test for `NULL` with `IS NULL`. If we want to filter out '<NA>' rows, we can use `IS NOT NULL` in `WHERE`.\n",
    "* `WHERE` operators include:\n",
    "\n",
    "| Operator | Description |\n",
    "|:---:|:---|\n",
    "| = | Equal |\n",
    "| > | Greater than |\n",
    "| < | Less than |\n",
    "| >= | Greater than or equal |\n",
    "| <= | Less than or equal |\n",
    "| <> or != | Not equal |\n",
    "| AND | Logical operator AND |\n",
    "| OR | Logical operator OR |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor[actor['first_name'].isin(['Chris','Cameron', 'Cuba'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor.query('first_name==\"Chris\" | first_name==\"Cameron\" | first_name==\"Cuba\" ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor[(actor['first_name'] == \"Chris\") | (actor['first_name'] == \"Cameron\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas note**\n",
    "\n",
    "* we can filter the dataframe using `.query('colname2>10 & colname2==\"abc\"')`. For or, using `|` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### What are the different rental durations that the store allows?\n",
    "\n",
    "**> idea:**\n",
    "Use `DISTINCT` operator together in `SELECT`\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select distinct rental_duration from film;\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "film.rental_duration.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> ### How many films are rated NC-17? How many are rated PG or PG-13?\n",
    "\n",
    "**> idea:**\n",
    "filter rows from films that are rated \"NC-17\", and use count command to see how many rows there are.\n",
    "If we want to check \"How many are rated PG or PG-13?\", in the where command, we can use `in` to filter rows that are in `('PG', 'PG-13')`\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select count(*) from film where rating in ('PG','PG-13');\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "film[film['rating'].isin(['PG','PG-13'])].groupby(['rating']).agg({'film_id':'count'}).reset_index().rename(columns={'film_id': 'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas note**\n",
    "\n",
    "* To summarise after groupby, we can use `.agg({'colname':'count'})`\n",
    "* To rename colnames, we can use `.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})`. Remember to use `columns` with s.\n",
    "\n",
    "Here are a list of method that we can use for `agg`\n",
    "\n",
    "| method |  |\n",
    "|:---:|:---|\n",
    "| 'sum' or np.sum | return the sum |\n",
    "| np.mean | Return the mean |\n",
    "| 'count' | return the count |\n",
    "| 'nunique' | Return the count of a number of different values |\n",
    "| 'max' | Return the maximum value |\n",
    "| 'min' | Return the minimum value |\n",
    "| np.std | Return the standard deviation |\n",
    "| np.var | Return the variance |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### How many different customers have entries in the rental table?\n",
    "\n",
    "**> idea:**\n",
    "Use distinct to get the unique id from the field `customer_id`, and then combine with `count` command to get the count number.\n",
    "\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select count(distinct customer_id) from rental;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rental['customer_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### What are the IDs of the last 5 customers to return a rental?\n",
    "\n",
    "**> idea:**\n",
    "order the `rental` table by `return_date` in descending order and get the `customer_id` of the first 3 rows\n",
    "\n",
    "\n",
    "**> solution:**\n",
    "\n",
    "```\n",
    "select customer_id, return_date from rental where customer_id=251 order by return_date DESC;\n",
    "```\n",
    "\n",
    "```\n",
    "select customer_id, count(*), max(return_date) from rental group by customer_id;\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "select customer_id, return_date from rental where return_date is not null order by return_date DESC limit 5;\n",
    "```\n",
    "\n",
    "**> better solution:**\n",
    "Since a customer_id can show up twice in the first five rows. To deduplicated this, we can do the following. Even though the result is the same, but it's a better solution.\n",
    "```\n",
    "select customer_id, recent_date from (\n",
    "  select customer_id, max(return_date) as recent_date from rental where return_date is not null group by customer_id \n",
    ") as tbl1 order by recent_date DESC limit 5;\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**> note:**\n",
    "\n",
    "* We can add `DESC` after `order by` to get the rows in descending order. If not specify, it will be ascending order.\n",
    "* If we want to filter out '<NA>' rows, we can use `IS NOT NULL` in `WHERE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rental.groupby(['customer_id']).agg({'return_date':'max'}).reset_index().sort_values(by=['return_date'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas note**\n",
    "\n",
    "* to sort values, we can use `.sort_values(by=['colname1','colnames2'], ascending=False)` to return value by descending order. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### Does the average replacement cost of a film differ by rating?\n",
    "\n",
    "**> idea:**\n",
    "We will want to `group by` rating and calculate the average replacement cost.\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select rating, avg(replacement_cost) from film group by rating;\n",
    "```\n",
    "\n",
    "\n",
    "**> note:**\n",
    "\n",
    "* All columns except the columns applied with some calculation in the `SELECT` part of the statement have to be in the GROUP BY part, or you'll get an error.\n",
    "* The [aggregate function](https://www.postgresql.org/docs/9.5/static/functions-aggregate.html) that can be used with `GROUP BY` include:\n",
    "\n",
    "| Name | Description |\n",
    "|:---:|:---|\n",
    "| avg() | Return the average value of the argument |\n",
    "| count() | Return a count of the number of rows returned |\n",
    "| count(distinct) | Return the count of a number of different values |\n",
    "| max() | Return the maximum value |\n",
    "| min() | Return the minimum value |\n",
    "| sum() | Return the sum |\n",
    "| stddev_pop | Return the population standard deviation |\n",
    "| stddev(), stddev_samp() | Return the sample standard deviation |\n",
    "| var_pop() | Return the population standard variance |\n",
    "| variance(), var_samp() | Return the sample variance |\n",
    "| array_agg() | input arrays concatenated into array of one higher dimension  |\n",
    "| json_agg | aggregates values as a JSON array | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "film.groupby(['rating']).agg({'replacement_cost':np.mean}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### Select film title that have \"Dragon\" in them.\n",
    "\n",
    "**> idea:**\n",
    "Using some command with `where` to filter our title with Dragon in them. It turns out the command we need is `similar to` combining with some wildcards.\n",
    "\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select * from film where title similar to '[C|F]%Dragon%';\n",
    "```\n",
    "\n",
    "\n",
    "**> note:**\n",
    "\n",
    "* `%` : The percent sign represents zero, one, or multiple characters\n",
    "* `_` : The underscore represents a single character\n",
    "* `'[bsp]%'`: The following SQL statement selects the target value starting with \"b\", \"s\", or \"p\"\n",
    "* `'[!bsp]%'`: The following SQL statement selects the target value NOT starting with \"b\", \"s\", or \"p\"\n",
    "    * We can also use `NOT LIKE '[bsp]%'`\n",
    "* `'[a-c]%'`: The following SQL statement selects the target value starting with \"a\", \"b\", or \"c\"\n",
    "* `'[a|c]%'`: denotes alternation (either of two alternatives). match value starting with either \"a\" or \"c\".\n",
    "* For more matching command, check [[here]](https://www.postgresql.org/docs/9.0/static/functions-matching.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "film[film['title'].str.contains(\"Dragon\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas note**\n",
    "\n",
    "* we can use `.str.contains(\"pattern\")` within filter to filter by string pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### Which store (store_id) has the most customers whose first name starts with M?\n",
    "\n",
    "**> idea:**\n",
    "We will probably need to filter out customer with 'first_name' starting with M, then group by `store_id`, and then count the distinct `customer_id`. (Actually, since `customer_id` is the primary key of the table, we don't need `distinct`.)\n",
    "\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select store_id, count(distinct customer_id) from customer where first_name similar to 'M%' group by store_id order by count(*) DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customer[customer['first_name'].str.startswith(\"M\")].groupby('store_id').agg({'customer_id':'count'}).reset_index().rename(columns={'customer_id':'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### Are there any customers with the same last name?\n",
    "\n",
    "**> idea:**\n",
    "We will probably want to `group by` `last_name` to check what are the `last_name` that is used ore than once. To do this, we will need to combine with `Having`\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select last_name, count(*) from customer group by last_name having count(*)>1;\n",
    "```\n",
    "It turns out that there is no customers with the same last name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customer.groupby(['last_name'])['customer_id'].count().reset_index().rename(columns={'customer_id':'count'}).query(\"count>1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas note**\n",
    "\n",
    "* we can filter the dataframe using `.query('colname>10')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### Which film (id) has the most actors?\n",
    "\n",
    "**> idea:**\n",
    "To do this, we will need to use `film_actor` table, `group by` `film_id` and count `actor_id`. Also, we'll want to sort by the count value.\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select film_id, count(actor_id) from film_actor group by film_id order by count(actor_id) DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "film_actor.groupby(['film_id'])['actor_id'].count().reset_index().rename(columns={'actor_id':'count'}).sort_values(by=['count'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### What films are actors with ids 129 and 195 in together?\n",
    "\n",
    "**> idea:**\n",
    "What we will need to do is first select films that `actor_id 129`is in. Then, out of those films, we then filter out films that `actor_id 195` is also in. Because we need to do twice, we'll need to use subquery\n",
    "\n",
    "**> solution:**\n",
    "\n",
    "```\n",
    "select film_id from film_actor where film_id IN (select film_id from film_actor where actor_id=129) and actor_id=195;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=film_actor.query('actor_id==129')\n",
    "b=film_actor.query('actor_id==195')\n",
    "c=pd.merge(a,b,on='film_id',how='left')\n",
    "\n",
    "c[(c.actor_id_y).notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas note**\n",
    "\n",
    "* to drop rows of Pandas DataFrame whose value in certain columns is NaN. We can use `df[df.colname.notnull()]` or `df[~df.colname.isnull()]`\n",
    "* to merge dataframes, we can use `pd.merge(df1,df2,  on='ad_id', how='left')`. \n",
    "    * how : {'left', 'right', 'outer', 'inner'}, default 'inner'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### How many actors are in more films than actor id 47? \n",
    "\n",
    "**> idea:**\n",
    "We'll firstly need to know how many film do actor 47 perform in. We then need to know how many films do each actors perform in. Then, we filter out the actors that performs more films than actor 47.\n",
    "\n",
    "Having the above table, we then count how many rows in the table.\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select count(*) from \n",
    "    (Select actor_id, count(*) from film_actor group by actor_id \n",
    "      having \n",
    "          count(*) > (select count(*) from film_actor where actor_id=47)\n",
    "    ) tbl1;\n",
    "```\n",
    "\n",
    "**> note:**\n",
    "\n",
    "* If we want to select from some temporary generated result set, we'll need to give our subquery a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id47 = film_actor.query('actor_id==47')['film_id'].count()\n",
    "\n",
    "film_actor.groupby('actor_id').agg({'film_id':'nunique'}).reset_index().rename(columns={'film_id':'count'}).query('count>@id47').head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas note**\n",
    "\n",
    "* to pass a variable into a query, we can use `.query('colname>@variable')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### Join the customer and payment tables together with an inner join; select customer id, name, amount, and date and order by customer id. Then join the staff table to them as well to add the staff's name.\n",
    "\n",
    "**> idea:**\n",
    "This is just to practice some command for inner join\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select * from \n",
    "  staff as s, \n",
    "  (select c.customer_id, c.first_name, c.last_name, p.amount, c.create_date, p.staff_id \n",
    "  from customer as c, payment as p where c.customer_id=p.customer_id \n",
    "  order by customer_id) tbl1 \n",
    "where s.staff_id=tbl1.staff_id; \n",
    "```\n",
    "```\n",
    "SELECT\n",
    " customer.customer_id,\n",
    " customer.first_name customer_first_name,\n",
    " customer.last_name customer_last_name,\n",
    " staff.first_name staff_first_name,\n",
    " staff.last_name staff_last_name,\n",
    " amount,\n",
    " payment_date\n",
    "FROM\n",
    " customer\n",
    "INNER JOIN payment ON payment.customer_id = customer.customer_id\n",
    "INNER JOIN staff ON payment.staff_id = staff.staff_id\n",
    "ORDER BY\n",
    " customer.customer_id;\n",
    "```\n",
    "\n",
    "**> note:**\n",
    "\n",
    "* We can use `WHERE r1.id=r2.id` or `INNER JOIN r2 on r1.id=r2.id` to do a inner join\n",
    "* When using `INNER JOIN` and `WHERE` together to filter something, `WHERE` should be used after the `INNER JOIN` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(customer,payment, on='customer_id',how='inner').rename(columns={'first_name':'customer_first','last_name':'customer_last'}).merge(staff,on='staff_id')[['customer_id','customer_first','customer_last','amount','create_date','staff_id','first_name','last_name']].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### Create a list of addresses that includes the name of the city instead of an ID number and the name of the country as well.\n",
    "\n",
    "**> idea:**\n",
    "We'll want to do a inner join using address and city, also address and country\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select \n",
    "  address, \n",
    "  address2,\n",
    "  city,\n",
    "  country\n",
    "from \n",
    "  address as a\n",
    "inner join city on a.city_id=city.city_id\n",
    "inner join country on city.country_id=country.country_id;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "address.merge(city,on='city_id',how='left').merge(country,on='country_id',how='left')[['address','city','country']].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### Which two actors have been in the most films together?\n",
    "\n",
    "**> idea:**\n",
    "It is a harder problem. To start, we will probably need to get a dataframe with actor_id 1 and actor_id 2 and the film_id. With this dataframe, we can then count how many rows do each of the two actor_id appears together in the dataframe. We can get the count by using `group by`.\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "SELECT a.actor_id, b.actor_id, count(*)\n",
    "FROM film_actor a, film_actor b -- join the table to itself\n",
    "WHERE a.film_id=b.film_id -- on the film id\n",
    "      AND a.actor_id > b.actor_id -- avoid duplicates and matching to the same actor\n",
    "GROUP BY a.actor_id, b.actor_id\n",
    "ORDER BY count(*) DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "film_actor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "film_actor.merge(film_actor,on='film_id').query('actor_id_x<actor_id_y').groupby(['actor_id_x','actor_id_y']).agg({'film_id':'count'}).reset_index().sort_values(by='film_id',ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### Get a list of the names of customers who have spent more than $150, along with their total spending.\n",
    "\n",
    "**> idea:**\n",
    "We can firstly get the `customer_id` that has spent more than $150 using payment. Then we join the result with the `customer` t o get the name.\n",
    "\n",
    "We can also firstly join `customer` to get all the names and then `group by` to filter out all the customers with payment over $150. The first version is more efficient, since it filter out before doing the join.\n",
    "\n",
    "**> solution:**\n",
    "\n",
    "```\n",
    "select c.first_name, c.last_name, c.customer_id, tbl1.sum\n",
    "from customer as c,\n",
    "  (select \n",
    "    p.customer_id, sum(amount) \n",
    "  from payment as p \n",
    "  group by customer_id having sum(amount) > 150) tbl1\n",
    "where c.customer_id = tbl1.customer_id\n",
    "order by sum DESC;\n",
    "```\n",
    "\n",
    "```\n",
    "select \n",
    "  c.first_name,\n",
    "  c.last_name,\n",
    "  sum(amount)\n",
    "from \n",
    "  customer as c,\n",
    "  payment as p\n",
    "where \n",
    "  c.customer_id=p.customer_id \n",
    "group by  \n",
    "  c.first_name, c.last_name\n",
    "having \n",
    "  sum(amount) > 150\n",
    "order by \n",
    "  sum(amount) DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "payment.groupby(['customer_id']).agg({'amount':'sum'}).reset_index().query('amount>150').merge(customer, on='customer_id', how='inner')[['customer_id','first_name','last_name','amount']].sort_values(by='amount',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='',\n",
    "                             db='world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city=pd.read_sql_query('SELECT * from city',con=connection)\n",
    "country=pd.read_sql_query('SELECT * from country',con=connection)\n",
    "language=pd.read_sql_query('SELECT * from country',con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "language.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Find the largest country in terms of population in each continent\n",
    "\n",
    "**> idea:**\n",
    "1. First have a table with column `continent, country, population`\n",
    "2. Get the country with the largest population for each continent from the table.\n",
    "\n",
    "The second part is tricky. We can not just `group by` continent and then select the max country by population. It's not that straight forward. \n",
    "\n",
    "We probably need to join the table by itself and then use some condition to get the conutry with the largest population. It's actually the same question as the problem1 from leetcode above.\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select * from city;\n",
    "```\n",
    "\n",
    "```{sql, connection=con_mysql}\n",
    "select \n",
    "    cn.Continent,\n",
    "    cn.Name,\n",
    "    sum(ci.Population) as population\n",
    "from \n",
    "  city as ci\n",
    "inner join country as cn on ci.CountryCode=cn.Code\n",
    "group by\n",
    "  ci.CountryCode\n",
    "order by\n",
    "  cn.Continent,\n",
    "  population DESC;\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "select \n",
    "  tbl1.Continent,\n",
    "  tbl1.Name,\n",
    "  tbl1.population\n",
    "from \n",
    "  (select \n",
    "      cn.Continent,\n",
    "      cn.Name,\n",
    "      sum(ci.Population) as population\n",
    "  from \n",
    "    city as ci\n",
    "  inner join country as cn on ci.CountryCode=cn.Code\n",
    "  group by\n",
    "    ci.CountryCode\n",
    "  order by\n",
    "    cn.Continent,\n",
    "    population DESC) as tbl1\n",
    "left join\n",
    "   (select \n",
    "        cn.Continent,\n",
    "        cn.Name,\n",
    "        sum(ci.Population) as population\n",
    "    from \n",
    "      city as ci\n",
    "    inner join country as cn on ci.CountryCode=cn.Code\n",
    "    group by\n",
    "      ci.CountryCode\n",
    "    order by\n",
    "      cn.Continent,\n",
    "      population DESC) as tbl2 \n",
    "  on \n",
    "    tbl1.Continent=tbl2.Continent and\n",
    "    tbl2.population > tbl1.population\n",
    "where \n",
    "  tbl2.population is NULL;\n",
    "```\n",
    "\n",
    "**> note:**\n",
    "\n",
    "* `inner join` should be before `group by`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Find the largest country (by area) in each continent, show the continent, the name and the area:\n",
    "\n",
    "**> idea:**\n",
    "1. We will need a table with column `continent, name, area`.\n",
    "2. We then want to get the largest country by area for each continent. \n",
    "\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select * from country;\n",
    "```\n",
    "\n",
    "```\n",
    "select \n",
    "  cn1.Continent, cn1.Name, cn1.SurfaceArea\n",
    "from\n",
    "  country as cn1\n",
    "left join\n",
    "  country as cn2 \n",
    "on \n",
    "  cn1.Continent = cn2.Continent and -- for every continent in cn1, it will join with the same continent in cn2.\n",
    "  cn2.SurfaceArea > cn1.SurfaceArea -- but we don't want to join country in each continent. We only want to join with the country which SurfaceArea is larger than the country in the left table. \n",
    "where \n",
    "  cn2.SurfaceArea is NULL; -- If the country in cn1 is the largest, then it will have no country from the right table to join. Therefore, it is the country we want. \n",
    "```\n",
    "\n",
    "```\n",
    "-- https://www.xaprb.com/blog/2006/12/07/how-to-select-the-firstleastmax-row-per-group-in-sql/\n",
    "-- correlated subquery\n",
    "SELECT -- not sure why -- ???\n",
    "  Continent, Name, SurfaceArea\n",
    "FROM country x\n",
    "WHERE SurfaceArea >= ALL\n",
    "    (SELECT SurfaceArea FROM country y\n",
    "    WHERE y.continent=x.continent\n",
    "    AND SurfaceArea>0);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country.sort_values(by='SurfaceArea',ascending=False).groupby('Continent').head(1)[['Continent','Name','SurfaceArea']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### List each continent and the name of the country that comes first alphabetically.\n",
    "\n",
    "**> idea:**\n",
    "1. we need to have a table have columns `continent, NAME`\n",
    "2. keep only the country with its name comes first alphabetically\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select \n",
    "  cn1.Continent,\n",
    "  cn1.Name \n",
    "from \n",
    "  country as cn1\n",
    "left join\n",
    "  country as cn2\n",
    "on \n",
    "  cn1.Continent=cn2.Continent and\n",
    "  cn2.Name < cn1.Name\n",
    "where \n",
    "  cn2.Name is NULL;\n",
    "```\n",
    "```\n",
    "SELECT Continent, Name\n",
    "FROM country x\n",
    "WHERE Name <= ALL(SELECT Name FROM country y WHERE y.Continent = x.Continent)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Find the continents where all countries have a population <= 25000000. Then find the names of the countries associated with these continents. Show name, continent and population.\n",
    "\n",
    "**> idea:**\n",
    "1. we need a table with columns `Continent, country, population`\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "-- ???\n",
    "SELECT Name, Continent, population\n",
    "FROM country x\n",
    "WHERE 25000000  > ALL(SELECT population FROM country y WHERE x.Continent = y.Continent AND y.population > 0)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Which countries have a GDP greater than every country in Europe? [Give the name only.] (Some countries may have NULL gdp values)\n",
    "\n",
    "**> idea:**\n",
    "1. select country name and then filter the rows using ALL command, continent!='Europe' and gdp!=NULL\n",
    "\n",
    "\n",
    "**> solution:**\n",
    "```\n",
    "select Name\n",
    "from country\n",
    "where \n",
    "  GNP > ALL(select GNP from country where Continent=\"Europe\" and GNP is NOT NULL) and \n",
    "  Continent!='Europe' and \n",
    "  GNP is NOT NULL;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Read csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no index column\n",
    "df = pd.read_csv('data/final_set.csv')\n",
    "\n",
    "# use the first column as index\n",
    "df = pd.read_csv('data/final_set.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Read Excel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/WHR2018Chapter2OnlineData.xls', sheet_name='Table2.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Drop Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['column1', 'column2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['column1', 'column2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Selecting columns in a pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df[['a','b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df.iloc[:,0:2] # Remember that Python does not slice inclusive of the ending index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df.iloc[0,0:2].copy() # To avoid the case where changing df1 also changes df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stackoverflow](https://stackoverflow.com/questions/11285613/selecting-columns-in-a-pandas-dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Check NA percentage for each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Filter NA rows in a specific column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df.colname.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Filter out rows with any NA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Filter with multiple conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[(df['country'].isin(final_set['country'])) & (df['year']==2008)].copy()\n",
    "df[(df['country'].isin(final_set['country'])) | (df['year']==2008)].copy()\n",
    "df[~df.countries.isin(countries)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **fill na in pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.fillna('someNewValue', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Save as csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('name.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Converting a column within pandas dataframe from int to string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['A']=df['A'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Create new column using some calculations on some current columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More than 2 cagetory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['newCol'] = df['oldCol'].apply(lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSeason(month):\n",
    "    \"\"\"\n",
    "    match season from month\n",
    "    \"\"\"\n",
    "    \n",
    "    if (month in [12,1,2]):\n",
    "        season = 'winter' \n",
    "    elif (month in [3,4,5]):\n",
    "        season = 'spring' \n",
    "    elif (month in [6,7,8]):\n",
    "        season = 'summer'\n",
    "    else:\n",
    "        season = 'fall'\n",
    "\n",
    "    return season   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tran_df['Transaction Month'].apply(lambda x: getSeason(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two category using list comprehension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_freq['frequency'] = ['F=1' if t == 1 else 'F>1' for t in df_freq['TranCount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **create confusion table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_actu = pd.Series([2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2], name='Actual’) \n",
    "y_pred = pd.Series([0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2], name='Predicted’) \n",
    "df_confusion = pd.crosstab(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Replace column values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['female'] = df['female'].map({'female': 1, 'male': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.female != 'female', 'female'] = 0\n",
    "df.loc[df.female == 'female', 'female'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **convert strings to date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime('2018/02/26 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime('2018/02/26 00:00:00').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date']).apply(lambda x: x.date()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **epoch/unit timestamp to datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " password_df['time'] = pd.to_datetime(password_df['time'], unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **convert strings to time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime('06:44:50', format='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime('06:44:50', format='%H:%M:%S').time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(df['Transaction Time'], format='%H:%M:%S').apply(lambda x: x.time()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **get hour/date from datetime column, assigning to a new column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['timestamp'] = df['timestamp'].astype('datetime64[ns]')\n",
    "df['date'] = df['timestamp'].apply(lambda x: x.date()) \n",
    "df['weekday'] = df['timestamp'].apply(lambda x: x.weekday()) \n",
    "df['month'] = df['timestamp'].apply(lambda x: x.month)\n",
    "df['hour'] = df['timestamp'].apply(lambda x: x.hour)\n",
    "df['minute'] = df['timestamp'].apply(lambda x: x.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['weekday'] = df['timestamp'].apply(lambda x: x.date().strftime('%A'))  # will return \"Wednesday\"\n",
    "df['weekday'] = df['timestamp'].apply(lambda x: x.date().strftime('%a'))  # will return \"Wed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [doc datetime](https://docs.python.org/3.3/library/datetime.html)\n",
    "* [stack](https://stackoverflow.com/questions/36341484/get-day-name-from-weekday-int/36341648)\n",
    "* [time symbol wildcard](https://docs.python.org/2/library/time.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How to get the value from a timedelta?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = datetime.timedelta(12045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(age.days)\n",
    "print(age.total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stackoverflow](https://stackoverflow.com/questions/27322362/how-to-get-the-value-from-a-timedelta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **add days to dates in dataframe; datetime add days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"X_DATE\"] = df[\"DATE\"] + timedelta(days=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add month\n",
    "df[\"X_DATE\"] = df[\"DATE\"] + pd.offsets.MonthOffset(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stack](https://stackoverflow.com/questions/46741423/add-months-to-a-date-in-pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **rbind, cbind**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rbind\n",
    "pd.concat([df1, df2])\n",
    "\n",
    "# cbind\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pivot method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'foo': ['one','one','one','two','two','two'],\n",
    "                       'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                       'baz': [1, 2, 3, 4, 5, 6]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.pivot(index='foo', columns='bar', values='baz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **pivot table method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use it when we need to have more than one column as index\n",
    "df_output = df.pivot_table(index=['col1', 'col2'], columns='metric', values='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Gather columns into rows by using melt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[doc](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'country': ['Taiwan','Japan'],\n",
    "                    '2011': [1, 2],\n",
    "                    '2012': [3, 4],\n",
    "                    '2013': [5, 6],\n",
    "                    '2014': [7, 8],                  \n",
    "                  })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.melt(id_vars='country')#,var_name='year', value_name='value'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Bin values based on ranges with pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stackoverflow](https://stackoverflow.com/questions/31736671/bin-values-based-on-ranges-with-pandas)\n",
    "\n",
    "[doc](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.cut.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.cut(x = pd.Series([1,5,75,125]), \n",
    "       bins = [0, 50, 100,200]\n",
    "      labels = [1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Print full dataframe in jupyter notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Getting the Row which has the max value in groups using groupby**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = df.groupby(['Profile ID'])['count'].transform(max) == df['count']\n",
    "df[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stackoverflow](https://stackoverflow.com/questions/15705630/python-getting-the-row-which-has-the-max-value-in-groups-using-groupby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **normalize columns in pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into response and predictors\n",
    "y = train_binary_dummy['isNDF']\n",
    "x = train_binary_dummy.drop('isNDF', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "def my_scaler(x):\n",
    "    \"\"\"standardize the predictors\"\"\"\n",
    "    \n",
    "    new_x = pd.DataFrame(scale(x, axis=0, with_mean=True, with_std=True, copy=True))\n",
    "    new_x.columns = x.columns\n",
    "    \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = my_scaler(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Drop duplicate rows in Python Pandas/ keep unique rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"A\":[\"foo\", \"foo\", \"foo\", \"bar\"], \"B\":[0,1,1,1], \"C\":[\"A\",\"A\",\"B\",\"A\"]})\n",
    "df.drop_duplicates(subset=['A', 'C'], keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep : {‘first’, ‘last’, False}, default ‘first’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[drop_duplicates doc](http://pandas.pydata.org/pandas-docs/version/0.17/generated/pandas.DataFrame.drop_duplicates.html)\n",
    "\n",
    "[stackoverflow](https://stackoverflow.com/questions/23667369/drop-all-duplicate-rows-in-python-pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Read and flatten json into pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "with open('../data/mpd.slice.0-999.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "song_df = json_normalize(data=data['playlists'], \n",
    "                         record_path='tracks', \n",
    "                         meta=['collaborative', 'duration_ms', 'modified_at', 'name', \n",
    "                               'num_albums', 'num_artists', 'num_edits', 'num_followers', 'num_tracks','pid', 'description'],\n",
    "                         record_prefix='track_',\n",
    "                         errors='ignore')\n",
    "\n",
    "# record_path: the nested key that we want to flatten\n",
    "# meta: the keys in the first level\n",
    "# record_prefix: the prefix for the keys in the nested level\n",
    "# error = ‘ignore’ : will ignore KeyError if keys listed in meta are not always present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [JSON to pandas DataFrame](https://stackoverflow.com/questions/21104592/json-to-pandas-dataframe)\n",
    "* [Document: pandas.io.json.json_normalize](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.json.json_normalize.html)\n",
    "* [Quick Tutorial: Flatten Nested JSON in Pandas\n",
    "](https://www.kaggle.com/jboysen/quick-tutorial-flatten-nested-json-in-pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Get difference between two lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp1 = ['One', 'Two', 'Three', 'Four']\n",
    "temp2 = ['One', 'Two']\n",
    "list(set(temp1) - set(temp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **group by count percentage for a categorical column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bar</th>\n",
       "      <th>foo</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>one</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>one</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>two</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>two</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>two</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bar  foo  value\n",
       "0   A  one      1\n",
       "1   A  one      2\n",
       "2   B  one      3\n",
       "3   B  two      4\n",
       "4   C  two      5\n",
       "5   C  two      6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'foo': ['one','one','one','two','two','two'],\n",
    "                       'bar': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "                       'value': [1, 2, 3, 4, 5, 6]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to calculate the percentage of A using the sum of value for each group in foo, we can use `crosstab` from pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foo</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   foo    A         B         C\n",
       "0  one  0.5  0.500000  0.000000\n",
       "1  two  0.0  0.266667  0.733333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_df = pd.crosstab(index=df['foo'],\n",
    "                              columns=df['bar'],\n",
    "                              values=df['value'],\n",
    "                              aggfunc=np.sum,\n",
    "                              dropna=False,\n",
    "                              normalize='index') \n",
    "percentage_df = percentage_df.reset_index()\n",
    "percentage_df.columns.name = None\n",
    "percentage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[crosstab doc](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.crosstab.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> **pandas create new column based on values from other columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_race (row):\n",
    "    if row['eri_hispanic'] == 1:\n",
    "        result = 'Hispanic'\n",
    "    elif row['eri_afr_amer'] + row['eri_asian'] + row['eri_hawaiian'] + row['eri_nat_amer'] + row['eri_white'] > 1 :\n",
    "        result = 'Two Or More'\n",
    "    else:     \n",
    "        result = 'White'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.apply (lambda row: label_race (row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stackoverflow](https://stackoverflow.com/questions/26886653/pandas-create-new-column-based-on-values-from-other-columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pandas: use groupby to count difference between dates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stackoverflow](https://stackoverflow.com/questions/38915186/pandas-use-groupby-to-count-difference-between-dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days_id = pd.DataFrame(duplicated_activate_records.groupby('id_os')['datepartition'].apply(lambda x: x.iloc[0] - x.iloc[-1])).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **get culmulative sum of a column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['cum_sum'] = df.val1.cumsum()\n",
    "df['cum_perc'] = 100*df.cum_sum/df.val1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **filter string contains**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stack](https://stackoverflow.com/questions/27975069/how-to-filter-rows-containing-a-string-pattern-from-a-pandas-dataframe/27975230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['ids'].str.contains(\"ball\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **create a sequence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stack](https://stackoverflow.com/questions/18265935/python-create-list-with-numbers-between-2-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "range(0, 7*12+1, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **faster way to transform string to datetime**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[reddit](https://www.reddit.com/r/learnpython/comments/6evlv5/faster_ways_to_convert_from_string_to_datetime/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_cache = {k: pd.to_datetime(k) for k in df['date'].unique()}\n",
    "df['date'] = df['date'].map(date_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **sum columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **select columns using iloc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.iloc[:,1:len(df.columns)] # select columns starting from the second column to the last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **divide multiple columns by another column in pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stack](https://stackoverflow.com/questions/34540567/divide-multiple-columns-by-another-column-in-pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydf= pd.DataFrame({'A':['a','b','c','d'],'D':[1,2,5,4],'E':[2,2,4,6],'F':[5,3,6,2]})\n",
    "mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydf[['E','F']] = mydf[['E','F']].div(mydf.D, axis=0)\n",
    "mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# equivalent to this\n",
    "mydf.iloc[:, 2:len(mydf.columns)] = mydf.iloc[:, 1:len(mydf.columns)].div(mydf.D, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **print whole dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **opposite of crosstab/pivot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydf= pd.DataFrame({'A':['a','b','c','d'],'D':[1,2,5,4],'E':[2,2,4,6],'F':[5,3,6,2]})\n",
    "mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.melt(mydf, id_vars=['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **multiple aggregations of the same column**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stack](https://stackoverflow.com/questions/17578115/pass-percentiles-to-pandas-agg-function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(\"dummy\").agg({\"value\": [np.mean, np.sum]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# percentile\n",
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    percentile_.__name__ = 'percentile_%s' % n\n",
    "    return percentile_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(\"dummy\").agg({\n",
    "    'value': [np.sum, np.mean, np.std, np.median, \n",
    "              np.min, percentile(25), percentile(75), np.max, \n",
    "              np.mean]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **sample a subset of rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pandas doc](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sample(frac=0.1, replace=False) # default false\n",
    "df.sample(frac=0.1, replace=True)\n",
    "df.sample(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **save model and load model sklearn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[blog](https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the model on 33%\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **see how long the python script runs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "print startTime\n",
    "\n",
    "# do a lot of things\n",
    "\n",
    "endTime = datetime.now()\n",
    "print startTime\n",
    "print endTime\n",
    "print startTime-endTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **convert categorical feature/column into numerical code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stack](https://stackoverflow.com/questions/32011359/convert-categorical-data-in-pandas-dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check dataframe type\n",
    "df.dtypes\n",
    "\n",
    "# set categorical features\n",
    "categorical = ['a','b']\n",
    "\n",
    "# transform multiple columns into categorical dtype\n",
    "df[categorical] = df[categorical].astype('category')\n",
    "\n",
    "# convert categorical feature into numerical code\n",
    "df[categorical] = df[categorical].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame({'id': [1,2,2],\n",
    "                    'device': ['device1', 'device2','device3']              \n",
    "                  })\n",
    "\n",
    "b = pd.DataFrame({'id': [1,1,2],\n",
    "                    'device': ['device1', 'device5','device6']              \n",
    "                  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **sort values by multiple columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw.sort_values(by=['Product Rank'], , ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **custom aggregation function using multiple columns**\n",
    "\n",
    "* [Learn More About Pandas By Building and Using a Weighted Average Function](http://pbpython.com/weighted-average.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavg(group, avg_name, weight_name):\n",
    "    \"\"\" http://stackoverflow.com/questions/10951341/pandas-dataframe-aggregate-function-using-multiple-columns\n",
    "    In rare instance, we may not have weights, so just return the mean. Customize this if your business case\n",
    "    should return otherwise.\n",
    "    \"\"\"\n",
    "    d = group[avg_name]\n",
    "    w = group[weight_name]\n",
    "    try:\n",
    "        return (d * w).sum() / w.sum()\n",
    "    except ZeroDivisionError:\n",
    "        return d.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wavg(sales, \"Current_Price\", \"Quantity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales.groupby(\"Manager\").apply(wavg, \"Current_Price\", \"Quantity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **rank by group**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link](http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_3[\"group_rank\"] = df_3.groupby(firstDim)[metric].rank(ascending=False,method='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **combine two column as list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_table['combine']=big_table[['a', 'b','c']].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **remove column with all zeros**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stack](https://stackoverflow.com/questions/21164910/delete-column-in-pandas-if-it-is-all-zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, (df != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **create dataframe pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     1     3\n",
       "1     2     4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **rename combine multiple level columns | flatten a hierarchical index in columns**\n",
    "\n",
    "* [How to flatten a hierarchical index in columns](https://stackoverflow.com/questions/14507794/python-pandas-how-to-flatten-a-hierarchical-index-in-columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  a  1\n",
       "1  a  2\n",
       "2  c  5\n",
       "3  c  4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf= pd.DataFrame({'A':['a','a','c','c'],'B':[1,2,5,4]})\n",
    "mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th colspan=\"2\" halign=\"left\">B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A    B       \n",
       "     mean median\n",
       "0  a  1.5    1.5\n",
       "1  c  4.5    4.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf = mydf.groupby('A').agg({'B':[np.mean, np.median]}).reset_index()\n",
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B_mean</th>\n",
       "      <th>B_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B_mean  B_median\n",
       "0  a     1.5       1.5\n",
       "1  c     4.5       4.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.columns = ['_'.join(col).strip() if col[1]!='' else col[0] for col in finaldf.columns.values]\n",
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=pd.merge(a,b,on='id',how='outer')\n",
    "c['same_device'] = c['device_x'] == c['device_y']\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.groupby('id')['same_device'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d0 = date(2018, 1, 28)\n",
    "d1 = date(2018, 7, 28)\n",
    "delta = d1 - d0\n",
    "print delta.days"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
